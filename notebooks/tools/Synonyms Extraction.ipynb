{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES\n",
    "\n",
    "#### Objective: \n",
    "This code aims at extracting synonyms of a given list of words from Merriam-Webster Dictionary through API call \n",
    "#### Synonyms extraction with given word lists:\n",
    "update the wordlists (restricted to 2k words, 1k per API KEY\n",
    "#### Analysis on extracted words:\n",
    "calculate count number of seed words, number of expanded words (exclude seedwords), expansion rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json \n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "API_KEY_1 = \"YOUR_API_KEY1\"\n",
    "API_KEY_2 ='YOUR_API_KEY2'\n",
    "\n",
    "\n",
    "# extract the raw synoynms using API call\n",
    "def extract_raw_syn_list(query_list,only_oneword_syn=True):\n",
    "    word_list = defaultdict(dict)\n",
    "    not_found_list=[]\n",
    "#     with Bar('Processing', max=len(query_list)) as bar:\n",
    "    count =0\n",
    "    for query in query_list:\n",
    "        count +=1\n",
    "        word_attr=defaultdict(list)\n",
    "        try:\n",
    "            url = \"https://www.dictionaryapi.com/api/v3/references/thesaurus/json/{}?key={}\".format(query,API_KEY_1)\n",
    "            query_js = requests.get(url).json()\n",
    "        except:\n",
    "            url = \"https://www.dictionaryapi.com/api/v3/references/thesaurus/json/{}?key={}\".format(query,API_KEY_2)\n",
    "            query_js = requests.get(url).json()\n",
    "        try:\n",
    "            for item in query_js:\n",
    "                    if item['hwi']['hw']==query: ## to extract only result contains one word only\n",
    "                        pos = item['fl'] ## get pos \n",
    "                        synset = item['meta']['syns'] ## get syn list for each entry\n",
    "                        synset = clean_syn_list(synset,only_oneword_syn)\n",
    "                        word_attr[pos]+=synset\n",
    "            word_list[query]=word_attr\n",
    "        except:\n",
    "             ## keep the failed keywords \n",
    "            not_found_list.append(query)\n",
    "            word_list[query]={}\n",
    "        if (count%100==0):\n",
    "            print(f\"count==>{count}\")\n",
    "    print(f'len of not_found:{len(not_found_list)}')\n",
    "    print(f'len of total valid seed words:{len(query_list)-len(not_found_list)}')\n",
    "    return word_list,not_found_list\n",
    "\n",
    "### keep only oneword synonyms only\n",
    "def clean_syn_list(synset,only_oneword_syn=True):\n",
    "    if only_oneword_syn:\n",
    "        for syn_list in synset:\n",
    "            for item in syn_list:\n",
    "                if item.find(' ')!=-1: ### remove synonyms that are more than one words\n",
    "                    syn_list.remove(item)\n",
    "    return synset\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Save the raw extraction to a txt file for future use\n",
    "\"\"\"\n",
    "def save_raw_extraction_as_json(raw_word_list,not_found_list, output_name=\"raw_extraction\"):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%d_%m_%H-%M-%S\")\n",
    "    word_list_filename = \"./{}{}.txt\".format(output_name,current_time)\n",
    "    not_fount_list_filename='./{}_not_found{}.txt'.format(output_name,current_time)\n",
    "    with open(word_list_filename,\"w+\") as f:\n",
    "        json.dump(raw_word_list,f)\n",
    "    with open(not_fount_list_filename,'w+')as f:\n",
    "        json.dump(not_found_list,f)\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "output word_list to csv ==> 3 columns\n",
    "word \n",
    "pos_sub= pos_num (indicate the pos and number of meaning of that pos )\n",
    "synlist = the syn list of that pos_sub\n",
    "\n",
    "\"\"\"\n",
    "def output_word_list(word_list,output_name=\"word_list\"):\n",
    "    pos_sub =[] \n",
    "    synset =[]\n",
    "    word_index =[] ## first column\n",
    "    for word, pos in word_list.items():\n",
    "        for pos,syn_set in pos.items():\n",
    "            count = 1\n",
    "            for syn_list in syn_set:\n",
    "                index_string = \"{}_{}_{:02d}\".format(word,pos,count)\n",
    "                pos_sub.append(index_string)\n",
    "                synset.append(syn_list)\n",
    "                count+=1\n",
    "                word_index+=[word]\n",
    "    new_pf = pd.DataFrame(np.array([word_index,pos_sub,synset]).T,columns=['word','pos_sub','synlist'])\n",
    "    return new_pf.to_csv(\"{}.csv\".format(output_name),index=False)\n",
    "\n",
    "\n",
    "def main(query_list,only_oneword_syn=True):\n",
    "    word_list,not_found_list = extract_raw_syn_list(query_list,only_oneword_syn)\n",
    "    save_raw_extraction_as_json(word_list,not_found_list)\n",
    "#     data = pd.DataFrame(word_list).T  ## index = word, columns = POS\n",
    "    output_word_list(word_list)\n",
    "    \n",
    "    \n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "#     ### update your query_list here\n",
    "#     pd = \n",
    "#     main(query_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms extraction with given word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = pd.read_excel('./syn/rank_imdb_rank_ngram.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of not_found:128\n",
      "len of total valid seed words:872\n"
     ]
    }
   ],
   "source": [
    "# query using the rank_imdb/rank_ngram percentage\n",
    "main(query_list['rank_imdb/rank_ngram'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis on the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first1k = pd.read_csv(\"./syn/first1k/word_list_1st.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_expand = set()\n",
    "\n",
    "for item_list in first1k['synlist']:\n",
    "    for item in re.findall('[a-zA-Z]+',item_list):\n",
    "        full_expand.add(item)\n",
    "seed_word = set(first1k['word'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "first1k['synlist_formatted']=first1k['synlist'].apply(lambda x: re.findall('[a-zA-Z]+',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_sub</th>\n",
       "      <th>synlist</th>\n",
       "      <th>synlist_formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indifference</td>\n",
       "      <td>indifference_noun_01</td>\n",
       "      <td>['apathy', 'casualness', 'complacence', 'disin...</td>\n",
       "      <td>[apathy, casualness, complacence, disintereste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>false_adjective_01</td>\n",
       "      <td>['erroneous', 'inaccurate', 'incorrect', 'inex...</td>\n",
       "      <td>[erroneous, inaccurate, incorrect, inexact, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false</td>\n",
       "      <td>false_adjective_02</td>\n",
       "      <td>['artificial', 'bogus', 'dummy', 'ersatz', 'fa...</td>\n",
       "      <td>[artificial, bogus, dummy, ersatz, factitious,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>false_adjective_03</td>\n",
       "      <td>['bogus', 'counterfeit', 'fake', 'forged', 'in...</td>\n",
       "      <td>[bogus, counterfeit, fake, forged, inauthentic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false</td>\n",
       "      <td>false_adjective_04</td>\n",
       "      <td>['affected', 'artificial', 'assumed', 'bogus',...</td>\n",
       "      <td>[affected, artificial, assumed, bogus, contriv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word               pos_sub  \\\n",
       "0  indifference  indifference_noun_01   \n",
       "1         false    false_adjective_01   \n",
       "2         false    false_adjective_02   \n",
       "3         false    false_adjective_03   \n",
       "4         false    false_adjective_04   \n",
       "\n",
       "                                             synlist  \\\n",
       "0  ['apathy', 'casualness', 'complacence', 'disin...   \n",
       "1  ['erroneous', 'inaccurate', 'incorrect', 'inex...   \n",
       "2  ['artificial', 'bogus', 'dummy', 'ersatz', 'fa...   \n",
       "3  ['bogus', 'counterfeit', 'fake', 'forged', 'in...   \n",
       "4  ['affected', 'artificial', 'assumed', 'bogus',...   \n",
       "\n",
       "                                   synlist_formatted  \n",
       "0  [apathy, casualness, complacence, disintereste...  \n",
       "1  [erroneous, inaccurate, incorrect, inexact, in...  \n",
       "2  [artificial, bogus, dummy, ersatz, factitious,...  \n",
       "3  [bogus, counterfeit, fake, forged, inauthentic...  \n",
       "4  [affected, artificial, assumed, bogus, contriv...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first1k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of seed words : 819\n",
      "number of expanded words (exclude seedwords) : 12182\n",
      "expansion rate 14.874236874236875\n"
     ]
    }
   ],
   "source": [
    "print(f'number of seed words : {len(seed_word)}')\n",
    "print(f'number of expanded words (exclude seedwords) : {len(full_expand - seed_word)}')\n",
    "print(f'expansion rate {len(full_expand - seed_word)/len(seed_word)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for item in first1k['synlist_formatted']:\n",
    "    total.extend(item)\n",
    "len(total)\n",
    "cnt = Counter(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6281"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict(filter(lambda elem: elem[1]>1,dict(cnt).items())).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>syn_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abruptly</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolute</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abyss</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceptable</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yea</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesterday</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            syn_len\n",
       "word               \n",
       "abruptly          2\n",
       "absolute         82\n",
       "abuse            51\n",
       "abyss             5\n",
       "acceptable       11\n",
       "...             ...\n",
       "write             4\n",
       "yea              16\n",
       "yesterday         4\n",
       "yet              33\n",
       "zip             108\n",
       "\n",
       "[820 rows x 1 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_word_syn_count = first1k[['word','syn_len']].groupby('word').sum()\n",
    "groupby_word_syn_count.loc[groupby_word_syn_count['syn_len']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "abruptly      1\n",
       "absolute      5\n",
       "abuse         6\n",
       "abyss         1\n",
       "acceptable    1\n",
       "             ..\n",
       "write         2\n",
       "yea           3\n",
       "yesterday     1\n",
       "yet           5\n",
       "zip           5\n",
       "Name: syn_len, Length: 827, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second1k[['word','syn_len']].groupby('word')['syn_len'].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
